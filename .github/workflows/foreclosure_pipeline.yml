name: Foreclosure Pipeline

on:
  schedule:
    - cron: '0 11 * * 1,2'  # Mon/Tue 6 AM EST
    - cron: '0 11 * * 4,5'  # Thu/Fri 6 AM EST
  workflow_dispatch:
    inputs:
      target_date:
        description: 'Target auction date (MM-DD-YYYY) or leave empty for all'
        required: false
        default: ''

env:
  SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
  SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}

jobs:
  scrape-and-analyze:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install httpx playwright aiohttp
          playwright install chromium --with-deps

      - name: Run Foreclosure Pipeline
        run: |
          if [ -n "${{ github.event.inputs.target_date }}" ]; then
            python scripts/brevard_foreclosure_pipeline.py "${{ github.event.inputs.target_date }}"
          else
            python scripts/brevard_foreclosure_pipeline.py
          fi

      - name: Push results to Supabase
        if: env.SUPABASE_URL != ''
        run: |
          python << 'PYTHON'
          import json
          import httpx
          import os
          from datetime import datetime

          SUPABASE_URL = os.environ.get('SUPABASE_URL')
          SUPABASE_KEY = os.environ.get('SUPABASE_KEY')

          if not SUPABASE_URL or not SUPABASE_KEY:
              print("Supabase not configured, skipping upload")
              exit(0)

          headers = {
              "apikey": SUPABASE_KEY,
              "Authorization": f"Bearer {SUPABASE_KEY}",
              "Content-Type": "application/json",
              "Prefer": "return=minimal"
          }

          # Load results
          with open('brevard_foreclosures.json') as f:
              data = json.load(f)

          # Insert activity log
          activity = {
              "activity_type": "foreclosure_pipeline",
              "description": f"Pipeline run: {data['total_cases']} cases, {data['recommendations']['BID']} BID, {data['recommendations']['REVIEW']} REVIEW",
              "metadata": {
                  "total_cases": data['total_cases'],
                  "active_cases": data['active_cases'],
                  "recommendations": data['recommendations'],
                  "run_time": datetime.now().isoformat()
              }
          }

          resp = httpx.post(
              f"{SUPABASE_URL}/rest/v1/activities",
              headers=headers,
              json=activity,
              timeout=30
          )
          print(f"Activity logged: {resp.status_code}")

          # Insert cases to foreclosure_auctions table
          inserted = 0
          for case in data['cases']:
              if case['status'] == 'CANCELLED':
                  continue
              
              auction_record = {
                  "case_number": case['case_number'],
                  "plaintiff": case['plaintiff'],
                  "defendant": case['defendant'],
                  "sale_date": case['sale_date'],
                  "status": case['status'],
                  "property_address": case.get('property_address'),
                  "judgment_amount": case.get('judgment_amount'),
                  "just_value": case.get('just_value'),
                  "recommendation": case.get('recommendation'),
                  "max_bid": case.get('max_bid'),
                  "photo_url": case.get('photo_url'),
                  "beds": case.get('beds'),
                  "baths": case.get('baths'),
                  "sqft": case.get('sqft'),
                  "scraped_at": datetime.now().isoformat()
              }
              
              try:
                  resp = httpx.post(
                      f"{SUPABASE_URL}/rest/v1/foreclosure_auctions",
                      headers={**headers, "Prefer": "resolution=merge-duplicates"},
                      json=auction_record,
                      timeout=10
                  )
                  if resp.status_code in [200, 201]:
                      inserted += 1
              except Exception as e:
                  print(f"Error inserting {case['case_number']}: {e}")

          print(f"Inserted/updated {inserted} cases to foreclosure_auctions")
          PYTHON

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: foreclosure-data-${{ github.run_number }}
          path: brevard_foreclosures.json
          retention-days: 30

      - name: Generate Summary
        run: |
          echo "## ðŸ  Foreclosure Pipeline Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          python3 << 'PYTHON' >> $GITHUB_STEP_SUMMARY
          import json
          with open('brevard_foreclosures.json') as f:
              data = json.load(f)
          
          print(f"**Run Time:** {data['generated_at']}")
          print(f"")
          print(f"| Metric | Count |")
          print(f"|--------|-------|")
          print(f"| Total Cases | {data['total_cases']} |")
          print(f"| Active | {data['active_cases']} |")
          print(f"| ðŸŸ¢ BID | {data['recommendations']['BID']} |")
          print(f"| ðŸŸ¡ REVIEW | {data['recommendations']['REVIEW']} |")
          print(f"| ðŸ”´ SKIP | {data['recommendations']['SKIP']} |")
          PYTHON
